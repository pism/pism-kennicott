{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4aaf0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import pylab as plt\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import nc_time_axis\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import contextlib\n",
    "from glob import glob\n",
    "from functools import reduce\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.lines as mlines\n",
    "matplotlib.use(\"QtAgg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefe8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        \"\"\"TQDM Callback\"\"\"\n",
    "\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c4a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kennicott-profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c21dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"x\"].values\n",
    "surface = df[\"elevation\"].values\n",
    "x = np.hstack([x, 60e3])\n",
    "surface = np.hstack([surface, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d315ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 100\n",
    "Lx = 60e3\n",
    "nx = int(Lx / dx)\n",
    "x_new = np.linspace(dx, Lx, nx)\n",
    "f = interp1d(x, surface, kind=\"quadratic\")\n",
    "surface_new = f(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d90bb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(data=np.vstack([x_new, surface_new, surface_new]).T, columns=[\"x\", \"bed\", \"surface\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e865d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"kennicott-profile-100m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff60a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "uq_df = pd.read_csv(\"ensemble_kennicott_climate_flow_lhs_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b585603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ensemble(m_file, params_df):\n",
    "    with xr.open_dataset(m_file) as ds:\n",
    "        m_id = int(m_file.split(\".\")[0].split(\"_\")[-3])\n",
    "        x = ds[\"x\"] / 1e3\n",
    "        bed = ds[\"topg\"][-1,-1,:]\n",
    "        thickness = ds[\"thk\"][-1,-1,:]\n",
    "        surface = ds[\"usurf\"][-1,-1,:]\n",
    "        surface_speed = ds[\"velsurf_mag\"][-1,-1,:]\n",
    "        surface_speed = surface_speed\n",
    "        basal_speed = ds[\"velbase_mag\"][-1,-1,:]\n",
    "        basal_speed = basal_speed.where(thickness>10)\n",
    "        temp_pa = ds[\"temp_pa\"][-1,-1,:, 0]\n",
    "        temp_pa = temp_pa.where(thickness>10)\n",
    "        params = params_df[params_df[\"id\"] == m_id]\n",
    "        ela =  params[\"ela\"].values[0]\n",
    "        warnings.filterwarnings('ignore')\n",
    "        try:\n",
    "            f = interp1d(surface, x)\n",
    "            x_ela = f(ela)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            f = interp1d(x, thickness)\n",
    "            thickness_ela = f(x_ela)\n",
    "        except:\n",
    "            thickness_ela = np.nan\n",
    "        try:\n",
    "            f = interp1d(x, surface_speed)\n",
    "            surface_speed_ela = f(x_ela)\n",
    "        except:\n",
    "            surface_speed_ela = np.nan\n",
    "        try:\n",
    "            f = interp1d(x, basal_speed)\n",
    "            basal_speed_ela = f(x_ela)\n",
    "        except:\n",
    "            basal_speed_ela = np.nan\n",
    "        try:\n",
    "            f = interp1d(x, temp_pa)\n",
    "            temp_pa_ela = f(x_ela)\n",
    "        except:\n",
    "            temp_pa_ela = np.nan\n",
    "        log_like = 0.0\n",
    "        try:\n",
    "            idx = np.where(thickness.where(surface<3000)[:].values == 0)[0]\n",
    "            if len(idx) != 0:\n",
    "                exp = x.to_numpy()[idx[0]]\n",
    "                log_like -= 0.5 * (\n",
    "                    (exp - observed_mean) / observed_std\n",
    "                    ) ** 2 + 0.5 * np.log(2 * np.pi * observed_std**2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    d =  {\"id\": m_id, \n",
    "            \"data\": {\"x\": x, \n",
    "                     \"thickness\": thickness.to_numpy(),\n",
    "                     \"bed\": bed.to_numpy(),\n",
    "                     \"surface\": surface.to_numpy(), \n",
    "                     \"surface_speed\": surface_speed.to_numpy(), \n",
    "                     \"basal_speed\": basal_speed.to_numpy(), \n",
    "                     \"temp_pa\": temp_pa.to_numpy(), \n",
    "                     \"ela\": ela,\n",
    "                     \"thickness_ela\": thickness_ela,\n",
    "                     \"surface_speed_ela\": surface_speed_ela,\n",
    "                     \"basal_speed_ela\": basal_speed_ela}}\n",
    "    if log_like != 0:\n",
    "        d[\"data\"][\"log_like\"] = log_like\n",
    "    return d\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "be0408bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 6\n",
    "lw = 1.0\n",
    "aspect_ratio = 1\n",
    "markersize = 1\n",
    "\n",
    "params = {\n",
    "    \"backend\": \"ps\",\n",
    "    \"axes.linewidth\": 0.25,\n",
    "    \"lines.linewidth\": lw,\n",
    "    \"axes.labelsize\": fontsize,\n",
    "    \"font.size\": fontsize,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"xtick.labelsize\": fontsize,\n",
    "    \"xtick.major.size\": 2.5,\n",
    "    \"xtick.major.width\": 0.25,\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"ytick.labelsize\": fontsize,\n",
    "    \"ytick.major.size\": 2.5,\n",
    "    \"ytick.major.width\": 0.25,\n",
    "    \"legend.fontsize\": fontsize,\n",
    "    \"lines.markersize\": markersize,\n",
    "    \"font.size\": fontsize,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "cmap = sns.color_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "e1e80839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ensemble: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 919/919 [00:06<00:00, 151.53it/s]\n"
     ]
    }
   ],
   "source": [
    "observed_mean = 20\n",
    "observed_std = 1\n",
    "\n",
    "odir = \"2023_06_23_uq_climate_flow\"\n",
    "\n",
    "m_files = glob(f\"{odir}/state/kennicott_*0.nc\")\n",
    "n_files = len(m_files)\n",
    "n_jobs = 8\n",
    "\n",
    "with tqdm_joblib(tqdm(desc=\"Processing ensemble\", total=n_files)) as progress_bar:\n",
    "    df = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_ensemble)(\n",
    "            m_file, uq_df\n",
    "        )\n",
    "        for m_file in m_files\n",
    "    )\n",
    "    del progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "c779b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness_ela_df = pd.concat([pd.DataFrame(data=np.vstack([df[m][\"id\"], df[m][\"data\"][\"thickness_ela\"]]).T, columns=[\"id\", \"thickness_ela\"]) for m in range(len(df))])\n",
    "surface_speed_ela_df = pd.concat([pd.DataFrame(data=np.vstack([df[m][\"id\"], df[m][\"data\"][\"surface_speed_ela\"]]).T, columns=[\"id\", \"surface_speed_ela\"]) for m in range(len(df))])\n",
    "basal_speed_ela_df = pd.concat([pd.DataFrame(data=np.vstack([df[m][\"id\"], df[m][\"data\"][\"basal_speed_ela\"]]).T, columns=[\"id\", \"basal_speed_ela\"]) for m in range(len(df))])\n",
    "\n",
    "dfs = [uq_df, thickness_ela_df, surface_speed_ela_df, basal_speed_ela_df]\n",
    "\n",
    "all_glaciers_df = reduce(lambda  left,right: pd.merge(left,right,on=[\"id\"],\n",
    "                                            how='outer'), dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5569dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array([d[\"id\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "X = np.array([d[\"data\"][\"x\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Bed = np.array([d[\"data\"][\"bed\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Thickness = np.array([d[\"data\"][\"thickness\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Surface = np.array([d[\"data\"][\"surface\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Surface = np.where(Thickness>0, Surface, np.nan)\n",
    "Surface_speed = np.array([d[\"data\"][\"surface_speed\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Basal_speed = np.array([d[\"data\"][\"basal_speed\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Temp_pa = np.array([d[\"data\"][\"temp_pa\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "\n",
    "ids_l = np.array([d[\"id\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "X_l = np.array([d[\"data\"][\"x\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Thickness_l = np.array([d[\"data\"][\"thickness\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Surface_l = np.array([d[\"data\"][\"surface\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Surface_l = np.where(Thickness_l>0, Surface_l, np.nan)\n",
    "Surface_speed_l = np.array([d[\"data\"][\"surface_speed\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Basal_speed_l = np.array([d[\"data\"][\"basal_speed\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Temp_pa_l = np.array([d[\"data\"][\"temp_pa\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "\n",
    "last_ids = [np.where(np.isnan(Surface.T[k, :]))[0][1] - 1 for k in range(Surface.shape[1])]\n",
    "\n",
    "\n",
    "log_likes = np.array([d[\"data\"][\"log_like\"] for d in df if \"log_like\" in d[\"data\"]]).T\n",
    "id_log_likes = np.array([d[\"id\"] for d in df if \"log_like\" in d[\"data\"]]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "57aabc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = np.array(id_log_likes)\n",
    "w = np.array(log_likes)\n",
    "w -= w.mean()\n",
    "weights = np.exp(w)\n",
    "weights /= weights.sum()\n",
    "resampled_experiments = np.random.choice(experiments, len(experiments), p=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "7a64be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = pd.DataFrame(data=np.vstack([experiments, weights]).T, columns=[\"id\", \"weight\"])\n",
    "all_glaciers_with_weights = pd.merge(all_glaciers_df, resampled_df, on=\"id\", how=\"outer\").fillna(0)\n",
    "weights_min = all_glaciers_with_weights[\"weight\"].min()\n",
    "weights_max = all_glaciers_with_weights[\"weight\"].max()\n",
    "\n",
    "cmap = plt.get_cmap(\"magma\")\n",
    "cNorm = colors.Normalize(vmin=weights_min, vmax=weights_max)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "colorVals = scalarMap.to_rgba(range(len(uq_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "f5a9c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "thin = 5\n",
    "thin_l = 2\n",
    "with sns.axes_style(\"ticks\"): \n",
    "    fig, axs = plt.subplots(nrows=3, ncols=1, sharex=True, figsize=[3.6, 3.3], height_ratios=[1, 1, 2])\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1, wspace=0, hspace=0)\n",
    "    \n",
    "    cbar = plt.colormaps[\"magma\"]\n",
    "    m_colors = cbar(np.arange(cbar.N))\n",
    "    cax = axs[-1].inset_axes([0.7, 0.65, 0.25, 0.25])\n",
    "    cax.imshow([m_colors], extent=[0, 10, 0, 1])\n",
    "    cax.set_title(\"Likelihood\")\n",
    "    cax.set_xticks([0, 10])\n",
    "    cax.set_xticklabels([\"low\", \"high\"])\n",
    "    cax.set_yticks([])\n",
    "    axs[0].plot(X_l[:,::thin_l], Surface_speed_l[:, ::thin_l], color=\"0.75\", lw=0.2, ls=\"dotted\")\n",
    "    axs[0].plot(X[:, ::thin], Surface_speed[:, ::thin], color=\"0.25\", lw=0.5)\n",
    "#     axs[1].plot(X_l, Basal_speed_l, color=\"0.75\", lw=0.2)\n",
    "#     axs[1].plot(X, Basal_speed, color=\"0.25\", lw=0.5)\n",
    "    axs[1].plot(X_l[:, ::thin_l], Thickness_l[:, ::thin_l], color=\"0.75\", lw=0.2, ls=\"dotted\")\n",
    "    axs[1].plot(X[:, ::thin], Thickness[:, ::thin], color=\"0.25\", lw=.5)\n",
    "    axs[-1].plot(X_l[:, ::thin_l], Surface_l[:, ::thin_l], color=\"0.75\", lw=0.2, ls=\"dotted\")\n",
    "    axs[-1].plot(X[:, ::thin], Surface[:, ::thin], color=\"0.25\", lw=0.2)\n",
    "    for k in range(0, len(ids), thin):\n",
    "        m_id = ids[k]\n",
    "        w = all_glaciers_with_weights[all_glaciers_with_weights[\"id\"] == int(m_id)][\"weight\"].values[0]\n",
    "#         axs[-1].vlines(X[last_ids[k],], 0, Surface[last_ids[k], k], color=\"0.75\", lw=0.2)\n",
    "#         axs[-1].vlines(X[last_ids[k],], 0, Surface[last_ids[k], k], color=cmap(w / (weights_max-weights_min)), \n",
    "#                      alpha=w / (weights_max-weights_min), )\n",
    "        axs[0].plot(X[:, k], Surface_speed[:, k], \n",
    "                     color=cmap(w / (weights_max-weights_min)), \n",
    "                     alpha=w / (weights_max-weights_min), \n",
    "                     lw=0.5)\n",
    "#         axs[1].plot(X[::thin, k], Basal_speed[::thin, k], \n",
    "#                      color=cmap(w / (weights_max-weights_min)), \n",
    "#                      alpha=w / (weights_max-weights_min), \n",
    "#                      lw=0.5)\n",
    "        axs[1].plot(X[:, k], Thickness[:, k], \n",
    "                     color=cmap(w / (weights_max-weights_min)), \n",
    "                     alpha=w / (weights_max-weights_min), \n",
    "                     lw=0.5)\n",
    "        axs[-1].plot(X[:, k], Surface[:, k], \n",
    "                     color=cmap(w / (weights_max-weights_min)), \n",
    "                     alpha=w / (weights_max-weights_min), \n",
    "                     lw=0.5)\n",
    "#     axs[-1].fill_between(X[:, 0], np.zeros_like(Bed[:, 0]), np.zeros_like(Bed[:, 0]) + 500, \n",
    "#                          color=\"#9ecae1\", lw=0, zorder=-10)\n",
    "    axs[-1].plot(X, Bed[:, 0], color=\"k\")\n",
    "    axs[-1].fill_between(X[:, 0], np.zeros_like(Bed[:, 0]), Bed[:, 0], color=\"#fdbe85\")\n",
    "    axs[-1].axvline(observed_mean, color=\"#636363\", label=\"Mean\")\n",
    "    axs[-1].fill_betweenx([0, 3500], observed_mean-observed_std, \n",
    "                          observed_mean+observed_std, \n",
    "                          alpha=0.25, color=\"#636363\", lw=0, label=\"$\\pm 1-\\sigma$\")\n",
    "    axs[0].set_ylabel(\"Surface speed\\n(m/yr)\")\n",
    "    axs[0].set_ylim(0, 750)\n",
    "#     axs[1].set_ylabel(\"Basal Speed (m/yr)\")\n",
    "#     axs[1].set_ylim(0, 750)\n",
    "    axs[1].set_ylim(0, 1000)\n",
    "    axs[-1].set_ylim(0, 3500)\n",
    "    axs[-1].set_xlim(0, 60)\n",
    "    axs[1].set_ylabel(\"Ice thickness\\n(m)\")\n",
    "    axs[-1].set_ylabel(\"Elevation (m)\")\n",
    "    axs[-1].set_xlabel(\"Distance from bergschrund (km)\")\n",
    "    axs[-1].legend(loc=\"upper center\", title=\"Moraine Position\")\n",
    "    l = axs[-1].get_legend()\n",
    "    #l.get_frame().set_alpha(0)\n",
    "    l.get_frame().set_linewidth(0.25)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{odir}/kennicott_profile_plot.pdf\")\n",
    "\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "bb830600",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for e in resampled_experiments:\n",
    "    d.append(uq_df[uq_df[\"id\"] == int(e)])\n",
    "moraine_glaciers_df = pd.concat(d).reset_index(drop=True)\n",
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    sns_cmap = sns.color_palette(\"colorblind\")\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=4, sharey=True, figsize=[6.2, 2.4])\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1, wspace=-1, hspace=-1)\n",
    "    for k, v in enumerate([\"b_low\", \"b_high\", \"ela\", \"temp_ela\", \"lapse_rate\", \"sia_e\", \"phi\", \"pseudo_plastic_q\"]):\n",
    "        sns.histplot(data=moraine_glaciers_df, x=v, kde=True,\n",
    "                     color=sns_cmap[0],\n",
    "                     stat=\"probability\", ax=axs.ravel()[k])\n",
    "        axs.ravel()[k].set_xticks(axs.ravel()[k].get_xticks(), \n",
    "                                  axs.ravel()[k].get_xticklabels(), \n",
    "                                  rotation=90, ha='right')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{odir}/kennicott_parameter_posterior_hists.pdf\")\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "5ea71316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  id     b_low    b_high          ela   temp_ela  lapse_rate  \\\n",
      "Exp                                                                            \n",
      "Posterior  528.56592 -3.962390  3.198752  1143.930267 -11.766408   -5.968766   \n",
      "Prior      499.50000 -4.000017  3.000024  1099.994737 -12.000213   -5.999957   \n",
      "\n",
      "              sia_e        phi  pseudo_plastic_q  thickness_ela  \\\n",
      "Exp                                                               \n",
      "Posterior  2.532357  33.701960          0.627249      74.560782   \n",
      "Prior      2.499959  35.000152          0.625008     110.495838   \n",
      "\n",
      "           surface_speed_ela  basal_speed_ela  \n",
      "Exp                                            \n",
      "Posterior         369.534278       360.896697  \n",
      "Prior             291.395010       282.242900  \n"
     ]
    }
   ],
   "source": [
    "all_glaciers_df[\"Exp\"] = \"Prior\"\n",
    "moraine_glaciers_df[\"Exp\"] = \"Posterior\"\n",
    "dfs = [moraine_glaciers_df, thickness_ela_df, basal_speed_ela_df, surface_speed_ela_df]\n",
    "moraine_glaciers_df = reduce(lambda  left,right: pd.merge(left,right,on=[\"id\"],\n",
    "                                            how='outer'), dfs).reset_index(drop=True)\n",
    "\n",
    "merged_df = pd.concat([all_glaciers_df, moraine_glaciers_df]).reset_index(drop=True)\n",
    "median_df = merged_df.groupby(by=\"Exp\").median()\n",
    "mean_df = merged_df.groupby(by=\"Exp\").mean()\n",
    "print(mean_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "957d0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df = pd.DataFrame(data=np.vstack([experiments, weights]).T, columns=[\"id\", \"weight\"])\n",
    "a_df = pd.DataFrame(data=np.vstack([experiments, np.ones_like(experiments) / len(experiments)]).T, columns=[\"id\", \"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "29d0f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df = pd.merge(all_glaciers_df, m_df, on=\"id\")\n",
    "mm_df[\"Exp\"] = \"Posterior\"\n",
    "aa_df = pd.merge(all_glaciers_df, a_df, on=\"id\")\n",
    "aa_df[\"Exp\"] = \"Prior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "04a96d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_df = pd.concat([mm_df, aa_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "5a3f3bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/distributions.py:407: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  and estimate_kws[\"bins\"] == \"auto\"\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/distributions.py:407: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  and estimate_kws[\"bins\"] == \"auto\"\n"
     ]
    }
   ],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, axs = plt.subplots(ncols=2, sharey=True, figsize=(2.5, 1.1))\n",
    "    g = sns.histplot(data=am_df, x=\"thickness_ela\", weights=\"weight\", hue_order=[\"Prior\", \"Posterior\"],\n",
    "                 bins=np.linspace(25, 525, 11), palette=\"colorblind\",\n",
    "                 hue=\"Exp\", stat=\"probability\", \n",
    "                 multiple=\"dodge\", kde=True, kde_kws={\"clip\": [None, 525]}, ax=axs[0])\n",
    "    g = sns.histplot(data=am_df, x=\"surface_speed_ela\", weights=\"weight\", hue_order=[\"Prior\", \"Posterior\"],\n",
    "                 bins=np.linspace(0, 750, 12), palette=\"colorblind\",\n",
    "                 hue=\"Exp\", stat=\"probability\", \n",
    "                 multiple=\"dodge\", kde=True, kde_kws={\"clip\": [None, 750]}, ax=axs[1])\n",
    "# [axs[0].axvline(median_df[\"thickness_ela\"][e], color=sns_cmap[k], lw=.75) for k, e in enumerate(median_df.index)]\n",
    "[axs[0].axvline(mean_df[\"thickness_ela\"][e], color=sns_cmap[k], lw=.75, ls=\"dotted\") for k, e in enumerate(mean_df.index)]\n",
    "# [axs[1].axvline(median_df[\"surface_speed_ela\"][e], color=sns_cmap[k], lw=.75) for k, e in enumerate(median_df.index)]\n",
    "[axs[1].axvline(mean_df[\"surface_speed_ela\"][e], color=sns_cmap[k], lw=0.75, ls=\"dotted\") for k, e in enumerate(mean_df.index)]\n",
    "\n",
    "mean_line = mlines.Line2D(\n",
    "    [], [], color=\"k\", linewidth=0.75, ls=\"dotted\", label=\"Mean\"\n",
    "    )\n",
    "legend2 = axs[1].legend(handles=[mean_line], loc=\"upper right\")\n",
    "legend2.get_frame().set_linewidth(0.0)\n",
    "legend2.get_frame().set_alpha(0.0)\n",
    "axs[1].add_artist(legend2)\n",
    "\n",
    "axs[0].set_xlabel(\"Thickness (m)\")\n",
    "axs[1].set_xlabel(\"Surface Speed (m/yr)\")\n",
    "for k, ax in enumerate(axs):\n",
    "    l = ax.get_legend()\n",
    "    l.get_frame().set_alpha(0)\n",
    "    l.get_frame().set_linewidth(0.0)\n",
    "    l.get_title().set_text(None)\n",
    "    if k != 0:\n",
    "        l.remove()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{odir}/ela_pdfs.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f73a58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for e in ids_l:\n",
    "    d.append(uq_df[uq_df[\"id\"] == int(e)])\n",
    "too_big_glaciers_df = pd.concat(d).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2bb1ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    sns_cmap = sns.color_palette(\"colorblind\")\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=4, sharey=True, figsize=[6.2, 2.4])\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1, wspace=-1, hspace=-1)\n",
    "    for k, v in enumerate([\"b_low\", \"b_high\", \"ela\", \"temp_ela\", \"lapse_rate\", \"sia_e\", \"phi\", \"pseudo_plastic_q\"]):\n",
    "        sns.histplot(data=too_big_glaciers_df, x=v, kde=True,\n",
    "                     color=sns_cmap[0],\n",
    "                     stat=\"probability\", ax=axs.ravel()[k])\n",
    "        axs.ravel()[k].set_xticks(axs.ravel()[k].get_xticks(), \n",
    "                                  axs.ravel()[k].get_xticklabels(), \n",
    "                                  rotation=90, ha='right')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{odir}/kennicott_too_big_hists.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "5bc7ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\"b_low\": \"$b_{\\mathrm{low}}$ (m/yr)\", \n",
    "              \"b_high\": \"$b_{\\mathrm{high}}$ (m/yr)\", \n",
    "              \"ela\": \"$z_{\\mathrm{ELA}}$ (m)\", \n",
    "              \"lapse_rate\": \"$\\gamma_{T}$ (K / (1000m))\"}\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    sns_cmap = sns.color_palette(\"colorblind\")\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=[2.5, 2.1])\n",
    "    fig.subplots_adjust(bottom=0, top=1.0, left=0, right=1, wspace=0, hspace=0)\n",
    "    for k, v in enumerate([\"b_low\", \"b_high\", \n",
    "                           \"ela\",\n",
    "                           \"lapse_rate\"]):\n",
    "        ax = axs.ravel()[k]\n",
    "        sns.histplot(data=am_df, x=v, bins=10,\n",
    "                     kde=True,\n",
    "                     color=sns_cmap[0], \n",
    "                     hue=\"Exp\", hue_order=[\"Prior\", \"Posterior\"],\n",
    "                     palette=\"colorblind\",\n",
    "                     multiple=\"dodge\",\n",
    "                     weights=\"weight\", lw=0,\n",
    "                     stat=\"probability\", ax=ax)\n",
    "        l = axs.ravel()[k].get_legend()\n",
    "        l.get_frame().set_alpha(0)\n",
    "        l.get_frame().set_linewidth(0.0)\n",
    "        l.set_bbox_to_anchor([0.62, 0.68], transform = ax.transAxes)\n",
    "        l.get_title().set_text(None)\n",
    "        l.remove()\n",
    "        ax.set_xlabel(params_dict[v])\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{odir}/kennicott_param_hists_prior_posterior.pdf\")\n",
    "    del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e20d8b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open 2023_06_23_uq_climate_flow/kennicott_param_hists_prior_posterior.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "38b8b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open 2023_06_23_uq_climate_flow/ela_pdfs.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f6d8d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open 2023_06_23_uq_climate_flow/kennicott_profile_plot.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a6f460ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1       ,  0.1       ,  0.1       , ...,  0.1       ,\n",
       "         0.1       ,  0.1       ],\n",
       "       [ 0.35062762,  0.35062762,  0.35062762, ...,  0.35062762,\n",
       "         0.35062762,  0.35062762],\n",
       "       [ 0.60125523,  0.60125523,  0.60125523, ...,  0.60125523,\n",
       "         0.60125523,  0.60125523],\n",
       "       ...,\n",
       "       [59.49874477, 59.49874477, 59.49874477, ..., 59.49874477,\n",
       "        59.49874477, 59.49874477],\n",
       "       [59.74937238, 59.74937238, 59.74937238, ..., 59.74937238,\n",
       "        59.74937238, 59.74937238],\n",
       "       [60.        , 60.        , 60.        , ..., 60.        ,\n",
       "        60.        , 60.        ]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05898560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
