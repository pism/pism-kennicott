{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aaf0e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.interpolate import interp1d\n",
    "import pylab as plt\n",
    "import xarray as xr\n",
    "import seaborn as sns\n",
    "import nc_time_axis\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import joblib\n",
    "import contextlib\n",
    "from glob import glob\n",
    "from functools import reduce\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib.cm as cmx\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fefe8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def tqdm_joblib(tqdm_object):\n",
    "    \"\"\"Context manager to patch joblib to report into tqdm progress bar given as argument\"\"\"\n",
    "\n",
    "    class TqdmBatchCompletionCallback(joblib.parallel.BatchCompletionCallBack):\n",
    "        \"\"\"TQDM Callback\"\"\"\n",
    "\n",
    "        def __call__(self, *args, **kwargs):\n",
    "            tqdm_object.update(n=self.batch_size)\n",
    "            return super().__call__(*args, **kwargs)\n",
    "\n",
    "    old_batch_callback = joblib.parallel.BatchCompletionCallBack\n",
    "    joblib.parallel.BatchCompletionCallBack = TqdmBatchCompletionCallback\n",
    "    try:\n",
    "        yield tqdm_object\n",
    "    finally:\n",
    "        joblib.parallel.BatchCompletionCallBack = old_batch_callback\n",
    "        tqdm_object.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c4a64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"kennicott-profile.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c21dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df[\"x\"].values\n",
    "surface = df[\"elevation\"].values\n",
    "x = np.hstack([x, 60e3])\n",
    "surface = np.hstack([surface, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d315ee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 100\n",
    "Lx = 60e3\n",
    "nx = int(Lx / dx)\n",
    "x_new = np.linspace(dx, Lx, nx)\n",
    "f = interp1d(x, surface, kind=\"quadratic\")\n",
    "surface_new = f(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d90bb307",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = pd.DataFrame(data=np.vstack([x_new, surface_new, surface_new]).T, columns=[\"x\", \"bed\", \"surface\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9e865d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv(\"kennicott-profile-100m.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff60a024",
   "metadata": {},
   "outputs": [],
   "source": [
    "uq_df = pd.read_csv(\"ensemble_kennicott_climate_flow_lhs_1000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b585603e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ensemble(m_file, params_df):\n",
    "    with xr.open_dataset(m_file) as ds:\n",
    "        m_id = int(m_file.split(\".\")[0].split(\"_\")[-3])\n",
    "        x = ds[\"x\"]\n",
    "        bed = ds[\"topg\"][-1,-1,:]\n",
    "        thickness = ds[\"thk\"][-1,-1,:]\n",
    "        surface = ds[\"usurf\"][-1,-1,:]\n",
    "        surface_speed = ds[\"velsurf_mag\"][-1,-1,:]\n",
    "        surface_speed = surface_speed.where(thickness>10)\n",
    "        basal_speed = ds[\"velbase_mag\"][-1,-1,:]\n",
    "        basal_speed = basal_speed.where(thickness>10)\n",
    "        temp_pa = ds[\"temp_pa\"][-1,-1,:, 0]\n",
    "        temp_pa = temp_pa.where(thickness>10)\n",
    "        params = params_df[params_df[\"id\"] == m_id]\n",
    "        ela =  params[\"ela\"].values[0]\n",
    "        warnings.filterwarnings('ignore')\n",
    "        try:\n",
    "            f = interp1d(surface, x)\n",
    "            x_ela = f(ela)\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            f = interp1d(x, thickness)\n",
    "            thickness_ela = f(x_ela)\n",
    "        except:\n",
    "            thickness_ela = np.nan\n",
    "        try:\n",
    "            f = interp1d(x, surface_speed)\n",
    "            surface_speed_ela = f(x_ela)\n",
    "        except:\n",
    "            surface_speed_ela = np.nan\n",
    "        try:\n",
    "            f = interp1d(x, basal_speed)\n",
    "            basal_speed_ela = f(x_ela)\n",
    "        except:\n",
    "            basal_speed_ela = np.nan\n",
    "        try:\n",
    "            f = interp1d(x, temp_pa)\n",
    "            temp_pa_ela = f(x_ela)\n",
    "        except:\n",
    "            temp_pa_ela = np.nan\n",
    "        log_like = 0.0\n",
    "        try:\n",
    "            idx = np.where(thickness.where(surface<3000)[:].values == 0)[0]\n",
    "            if len(idx) != 0:\n",
    "                exp = x.to_numpy()[idx[0]]\n",
    "                log_like -= 0.5 * (\n",
    "                    (exp - observed_mean) / observed_std\n",
    "                    ) ** 2 + 0.5 * np.log(2 * np.pi * observed_std**2)\n",
    "        except ValueError:\n",
    "            pass\n",
    "    d =  {\"id\": m_id, \n",
    "            \"data\": {\"x\": x, \n",
    "                     \"thickness\": thickness.to_numpy(),\n",
    "                     \"bed\": bed.to_numpy(),\n",
    "                     \"surface\": surface.to_numpy(), \n",
    "                     \"surface_speed\": surface_speed.to_numpy(), \n",
    "                     \"basal_speed\": basal_speed.to_numpy(), \n",
    "                     \"temp_pa\": temp_pa.to_numpy(), \n",
    "                     \"ela\": ela,\n",
    "                     \"thickness_ela\": thickness_ela,\n",
    "                     \"surface_speed_ela\": surface_speed_ela,\n",
    "                     \"basal_speed_ela\": basal_speed_ela}}\n",
    "    if log_like != 0:\n",
    "        d[\"data\"][\"log_like\"] = log_like\n",
    "    return d\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be0408bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "fontsize = 6\n",
    "lw = 1.0\n",
    "aspect_ratio = 1\n",
    "markersize = 1\n",
    "\n",
    "params = {\n",
    "    \"backend\": \"ps\",\n",
    "    \"axes.linewidth\": 0.25,\n",
    "    \"lines.linewidth\": lw,\n",
    "    \"axes.labelsize\": fontsize,\n",
    "    \"font.size\": fontsize,\n",
    "    \"xtick.direction\": \"in\",\n",
    "    \"xtick.labelsize\": fontsize,\n",
    "    \"xtick.major.size\": 2.5,\n",
    "    \"xtick.major.width\": 0.25,\n",
    "    \"ytick.direction\": \"in\",\n",
    "    \"ytick.labelsize\": fontsize,\n",
    "    \"ytick.major.size\": 2.5,\n",
    "    \"ytick.major.width\": 0.25,\n",
    "    \"legend.fontsize\": fontsize,\n",
    "    \"lines.markersize\": markersize,\n",
    "    \"font.size\": fontsize,\n",
    "}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "cmap = sns.color_palette(\"colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e1e80839",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ensemble: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 803/803 [00:15<00:00, 51.16it/s]\n"
     ]
    }
   ],
   "source": [
    "observed_mean = 20_000\n",
    "observed_std = 1000\n",
    "\n",
    "odir = \"2023_06_23_uq_climate_flow/\"\n",
    "\n",
    "m_files = glob(f\"{odir}/state/kennicott_*0.nc\")\n",
    "n_files = len(m_files)\n",
    "n_jobs = 4\n",
    "\n",
    "with tqdm_joblib(tqdm(desc=\"Processing ensemble\", total=n_files)) as progress_bar:\n",
    "    df = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_ensemble)(\n",
    "            m_file, uq_df\n",
    "        )\n",
    "        for m_file in m_files\n",
    "    )\n",
    "    del progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c779b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "thickness_ela_df = pd.concat([pd.DataFrame(data=np.vstack([df[m][\"id\"], df[m][\"data\"][\"thickness_ela\"]]).T, columns=[\"id\", \"thickness_ela\"]) for m in range(len(df))])\n",
    "surface_speed_ela_df = pd.concat([pd.DataFrame(data=np.vstack([df[m][\"id\"], df[m][\"data\"][\"surface_speed_ela\"]]).T, columns=[\"id\", \"surface_speed_ela\"]) for m in range(len(df))])\n",
    "basal_speed_ela_df = pd.concat([pd.DataFrame(data=np.vstack([df[m][\"id\"], df[m][\"data\"][\"basal_speed_ela\"]]).T, columns=[\"id\", \"basal_speed_ela\"]) for m in range(len(df))])\n",
    "\n",
    "dfs = [uq_df, thickness_ela_df, surface_speed_ela_df, basal_speed_ela_df]\n",
    "\n",
    "all_glaciers_df = reduce(lambda  left,right: pd.merge(left,right,on=[\"id\"],\n",
    "                                            how='outer'), dfs).reset_index(drop=True)\n",
    "#all_glaciers_df = pd.merge(uq_df, thickness_ela_df, on=\"id\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5569dcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = np.array([d[\"id\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "X = np.array([d[\"data\"][\"x\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Bed = np.array([d[\"data\"][\"bed\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Surface = np.array([d[\"data\"][\"surface\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Thickness = np.array([d[\"data\"][\"thickness\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Surface_speed = np.array([d[\"data\"][\"surface_speed\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Basal_speed = np.array([d[\"data\"][\"basal_speed\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "Temp_pa = np.array([d[\"data\"][\"temp_pa\"] for d in df if d[\"data\"][\"thickness\"][-1] < 10]).T\n",
    "\n",
    "ids_l = np.array([d[\"id\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "X_l = np.array([d[\"data\"][\"x\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Surface_l = np.array([d[\"data\"][\"surface\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Thickness_l = np.array([d[\"data\"][\"thickness\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Surface_peed_l = np.array([d[\"data\"][\"surface_speed\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Basal_speed_l = np.array([d[\"data\"][\"basal_speed\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "Temp_pa_l = np.array([d[\"data\"][\"temp_pa\"] for d in df if d[\"data\"][\"thickness\"][-1] >= 10]).T\n",
    "\n",
    "\n",
    "log_likes = np.array([d[\"data\"][\"log_like\"] for d in df if \"log_like\" in d[\"data\"]]).T\n",
    "id_log_likes = np.array([d[\"id\"] for d in df if \"log_like\" in d[\"data\"]]).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "57aabc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = np.array(id_log_likes)\n",
    "w = np.array(log_likes)\n",
    "w -= w.mean()\n",
    "weights = np.exp(w)\n",
    "weights /= weights.sum()\n",
    "resampled_experiments = np.random.choice(experiments, len(experiments), p=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7a64be2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resampled_df = pd.DataFrame(data=np.vstack([experiments, weights]).T, columns=[\"id\", \"weight\"])\n",
    "all_glaciers_with_weights = pd.merge(all_glaciers_df, resampled_df, on=\"id\", how=\"outer\").fillna(0)\n",
    "weights_min = all_glaciers_with_weights[\"weight\"].min()\n",
    "weights_max = all_glaciers_with_weights[\"weight\"].max()\n",
    "\n",
    "cmap = plt.get_cmap(\"magma\")\n",
    "cNorm = colors.Normalize(vmin=weights_min, vmax=weights_max)\n",
    "scalarMap = cmx.ScalarMappable(norm=cNorm, cmap=cmap)\n",
    "colorVals = scalarMap.to_rgba(range(len(uq_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5a9c17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"): \n",
    "    fig, axs = plt.subplots(nrows=4, ncols=1, sharex=True, figsize=[6.2, 5.2], height_ratios=[1, 1, 1, 2])\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1, wspace=0, hspace=0)\n",
    "    \n",
    "    cbar = plt.colormaps[\"magma\"]\n",
    "    m_colors = cbar(np.arange(cbar.N))\n",
    "    cax = axs[0].inset_axes([0.7, 0.5, 0.25, 0.25])\n",
    "    cax.imshow([m_colors], extent=[0, 10, 0, 1])\n",
    "    cax.set_title(\"Likelihood\")\n",
    "    cax.set_xticks([0, 10])\n",
    "    cax.set_xticklabels([\"low\", \"high\"])\n",
    "    cax.set_yticks([])\n",
    "    axs[0].plot(X_l, Surface_peed_l, color=\"0.75\", lw=0.2)\n",
    "    axs[0].plot(X, Surface_speed, color=\"0.25\", lw=0.5)\n",
    "    axs[1].plot(X_l, Basal_speed_l, color=\"0.75\", lw=0.2)\n",
    "    axs[1].plot(X, Basal_speed, color=\"0.25\", lw=0.5)\n",
    "    axs[2].plot(X_l, Thickness_l, color=\"0.75\", lw=0.2)\n",
    "    axs[2].plot(X, Thickness, color=\"0.25\", lw=.5)\n",
    "    axs[-1].plot(X_l, Surface_l, color=\"0.75\", lw=0.2)\n",
    "    axs[-1].plot(X, Surface, color=\"0.25\", lw=0.2)\n",
    "    for k in range(len(ids)):\n",
    "        m_id = ids[k]\n",
    "        w = all_glaciers_with_weights[all_glaciers_with_weights[\"id\"] == int(m_id)][\"weight\"].values[0]\n",
    "        axs[0].plot(X[:, k], Surface_speed[:, k], \n",
    "                     color=cmap(w / (weights_max-weights_min)), \n",
    "                     alpha=w / (weights_max-weights_min), \n",
    "                     lw=0.5)\n",
    "        axs[1].plot(X[:, k], Basal_speed[:, k], \n",
    "                     color=cmap(w / (weights_max-weights_min)), \n",
    "                     alpha=w / (weights_max-weights_min), \n",
    "                     lw=0.5)\n",
    "        axs[2].plot(X[:, k], Thickness[:, k], \n",
    "                     color=cmap(w / (weights_max-weights_min)), \n",
    "                     alpha=w / (weights_max-weights_min), \n",
    "                     lw=0.5)\n",
    "        axs[-1].plot(X[:, k], Surface[:, k], \n",
    "                     color=cmap(w / (weights_max-weights_min)), \n",
    "                     alpha=w / (weights_max-weights_min), \n",
    "                     lw=0.5)\n",
    "    axs[-1].plot(X, Bed[:, 0], color=\"k\")\n",
    "    axs[-1].fill_between(X[:, 0], np.zeros_like(Bed[:, 0]), Bed[:, 0], color=\"#fdbe85\")\n",
    "    axs[-1].fill_betweenx([0, 3500], observed_mean-observed_std, \n",
    "                          observed_mean+observed_std, alpha=0.5, label=\"moraine position\")\n",
    "    axs[-1].axvline(observed_mean)\n",
    "    axs[0].set_ylabel(\"Surface peed (m/yr)\")\n",
    "    axs[0].set_ylim(0, 750)\n",
    "    axs[1].set_ylabel(\"Basal Speed (m/yr)\")\n",
    "    axs[1].set_ylim(0, 750)\n",
    "    axs[2].set_ylim(0, 1000)\n",
    "    axs[-1].set_ylim(0, 3500)\n",
    "    axs[-1].set_xlim(0, 60000)\n",
    "    axs[2].set_ylabel(\"Ice thickness (m)\")\n",
    "    axs[-1].set_ylabel(\"Elevation (m)\")\n",
    "    axs[-1].set_xlabel(\"Distance from bergschrund (m)\")\n",
    "    axs[-1].legend()\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(f\"{odir}/kennicott_profile_plot.pdf\")\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bb830600",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for e in resampled_experiments:\n",
    "    d.append(uq_df[uq_df[\"id\"] == int(e)])\n",
    "moraine_glaciers_df = pd.concat(d).reset_index(drop=True)\n",
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    sns_cmap = sns.color_palette(\"colorblind\")\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=4, sharey=True, figsize=[6.2, 2.4])\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1, wspace=-1, hspace=-1)\n",
    "    for k, v in enumerate([\"b_low\", \"b_high\", \"ela\", \"temp_ela\", \"lapse_rate\", \"sia_e\", \"phi\", \"pseudo_plastic_q\"]):\n",
    "        sns.histplot(data=moraine_glaciers_df, x=v, kde=True,\n",
    "                     color=sns_cmap[0],\n",
    "                     stat=\"probability\", ax=axs.ravel()[k])\n",
    "        axs.ravel()[k].set_xticks(axs.ravel()[k].get_xticks(), \n",
    "                                  axs.ravel()[k].get_xticklabels(), \n",
    "                                  rotation=90, ha='right')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{odir}/kennicott_parameter_posterior_hists.pdf\")\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "957d0094",
   "metadata": {},
   "outputs": [],
   "source": [
    "m_df = pd.DataFrame(data=np.vstack([experiments, weights]).T, columns=[\"id\", \"weight\"])\n",
    "a_df = pd.DataFrame(data=np.vstack([experiments, np.ones_like(experiments) / len(experiments)]).T, columns=[\"id\", \"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29d0f44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_df = pd.merge(all_glaciers_df, m_df, on=\"id\")\n",
    "mm_df[\"Exp\"] = \"Posterior\"\n",
    "aa_df = pd.merge(all_glaciers_df, a_df, on=\"id\")\n",
    "aa_df[\"Exp\"] = \"Prior\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04a96d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "am_df = pd.concat([mm_df, aa_df]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5ea71316",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_glaciers_df[\"Exp\"] = \"Prior\"\n",
    "moraine_glaciers_df[\"Exp\"] = \"Posterior\"\n",
    "dfs = [moraine_glaciers_df, thickness_ela_df, basal_speed_ela_df, surface_speed_ela_df]\n",
    "morain_glaciers_df = reduce(lambda  left,right: pd.merge(left,right,on=[\"id\"],\n",
    "                                            how='outer'), dfs).reset_index(drop=True)\n",
    "\n",
    "merged_df = pd.concat([all_glaciers_df, moraine_glaciers_df]).reset_index(drop=True)\n",
    "median_df = merged_df.groupby(by=\"Exp\").median()\n",
    "mean_df = merged_df.groupby(by=\"Exp\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5a3f3bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/distributions.py:407: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  and estimate_kws[\"bins\"] == \"auto\"\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/distributions.py:407: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  and estimate_kws[\"bins\"] == \"auto\"\n",
      "/opt/local/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/seaborn/distributions.py:407: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  and estimate_kws[\"bins\"] == \"auto\"\n"
     ]
    }
   ],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    fig, axs = plt.subplots(ncols=3, sharey=True, figsize=(4.2, 1.4))\n",
    "    g = sns.histplot(data=am_df, x=\"thickness_ela\", weights=\"weight\", hue_order=[\"Prior\", \"Posterior\"],\n",
    "                 bins=np.linspace(25, 525, 11), palette=\"colorblind\",\n",
    "                 hue=\"Exp\", stat=\"probability\", \n",
    "                 multiple=\"dodge\", kde=True, kde_kws={\"clip\": [None, 525]}, ax=axs[0])\n",
    "    g = sns.histplot(data=am_df, x=\"basal_speed_ela\", weights=\"weight\", hue_order=[\"Prior\", \"Posterior\"],\n",
    "                 bins=np.linspace(0, 750, 12), palette=\"colorblind\",\n",
    "                 hue=\"Exp\", stat=\"probability\", \n",
    "                 multiple=\"dodge\", kde=True, kde_kws={\"clip\": [None, 750]}, ax=axs[1])\n",
    "    g = sns.histplot(data=am_df, x=\"surface_speed_ela\", weights=\"weight\", hue_order=[\"Prior\", \"Posterior\"],\n",
    "                 bins=np.linspace(0, 750, 12), palette=\"colorblind\",\n",
    "                 hue=\"Exp\", stat=\"probability\", \n",
    "                 multiple=\"dodge\", kde=True, kde_kws={\"clip\": [None, 750]}, ax=axs[2])\n",
    "[axs[0].axvline(median_df[\"thickness_ela\"][e], color=sns_cmap[k], lw=.75) for k, e in enumerate(median_df.index)]\n",
    "[axs[0].axvline(mean_df[\"thickness_ela\"][e], color=sns_cmap[k], lw=.75, ls=\"dotted\") for k, e in enumerate(mean_df.index)]\n",
    "[axs[1].axvline(median_df[\"basal_speed_ela\"][e], color=sns_cmap[k], lw=.75) for k, e in enumerate(median_df.index)]\n",
    "[axs[1].axvline(mean_df[\"basal_speed_ela\"][e], color=sns_cmap[k], lw=.75, ls=\"dotted\") for k, e in enumerate(mean_df.index)]\n",
    "[axs[2].axvline(median_df[\"surface_speed_ela\"][e], color=sns_cmap[k], lw=.75) for k, e in enumerate(median_df.index)]\n",
    "[axs[2].axvline(mean_df[\"surface_speed_ela\"][e], color=sns_cmap[k], lw=0.75, ls=\"dotted\") for k, e in enumerate(mean_df.index)]\n",
    "\n",
    "for k, ax in enumerate(axs):\n",
    "    l = ax.get_legend()\n",
    "    l.get_frame().set_alpha(0)\n",
    "    l.get_frame().set_linewidth(0.0)\n",
    "    l.get_title().set_text(None)\n",
    "    if k != 0:\n",
    "        l.remove()\n",
    "\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{odir}/ela_pdfs.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f73a58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = []\n",
    "for e in ids_l:\n",
    "    d.append(uq_df[uq_df[\"id\"] == int(e)])\n",
    "too_big_glaciers_df = pd.concat(d).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2bb1ed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with sns.axes_style(\"ticks\"):\n",
    "    sns_cmap = sns.color_palette(\"colorblind\")\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=4, sharey=True, figsize=[6.2, 2.4])\n",
    "    fig.subplots_adjust(bottom=0, top=1, left=0, right=1, wspace=-1, hspace=-1)\n",
    "    for k, v in enumerate([\"b_low\", \"b_high\", \"ela\", \"temp_ela\", \"lapse_rate\", \"sia_e\", \"phi\", \"pseudo_plastic_q\"]):\n",
    "        sns.histplot(data=too_big_glaciers_df, x=v, kde=True,\n",
    "                     color=sns_cmap[0],\n",
    "                     stat=\"probability\", ax=axs.ravel()[k])\n",
    "        axs.ravel()[k].set_xticks(axs.ravel()[k].get_xticks(), \n",
    "                                  axs.ravel()[k].get_xticklabels(), \n",
    "                                  rotation=90, ha='right')\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{odir}/kennicott_too_big_hists.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e5266daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "    g = sns.PairGrid(\n",
    "        moraine_glaciers_df.drop(columns=[\"id\"]),\n",
    "        diag_sharey=False,\n",
    "        height=1.0,\n",
    "    )\n",
    "\n",
    "    g.map_upper(sns.scatterplot, s=2, color=\"0.5\", rasterized=True)\n",
    "    g.map_lower(sns.kdeplot, levels=4, color=\"k\", linewidths=0.5)\n",
    "    g.map_diag(sns.kdeplot, lw=1.0, color=\"k\")\n",
    "    g.figure.savefig(f\"{odir}/pair.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00d6b061",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open 2023_06_23_uq_climate_flow/*pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5bc7ab0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style(\"ticks\"):\n",
    "    sns_cmap = sns.color_palette(\"colorblind\")\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=4, sharey=True, figsize=[6.2, 2.4])\n",
    "    fig.subplots_adjust(bottom=0, top=1.0, left=0, right=1, wspace=0, hspace=-1)\n",
    "    for k, v in enumerate([\"b_low\", \"b_high\", \n",
    "                           \"ela\", \"temp_ela\", \n",
    "                           \"lapse_rate\", \"sia_e\", \n",
    "                           \"phi\", \"pseudo_plastic_q\"]):\n",
    "        ax = axs.ravel()[k]\n",
    "        sns.histplot(data=am_df, x=v, bins=10,\n",
    "                     kde=True,\n",
    "                     color=sns_cmap[0], hue=\"Exp\", palette=\"colorblind\",\n",
    "                     multiple=\"dodge\",\n",
    "                     weights=\"weight\", lw=0,\n",
    "                     stat=\"probability\", ax=ax)\n",
    "        axs.ravel()[k].set_xticks(ax.get_xticks(), \n",
    "                                  ax.get_xticklabels(), \n",
    "                                  rotation=90, ha='right')\n",
    "        l = axs.ravel()[k].get_legend()\n",
    "        l.get_frame().set_alpha(0)\n",
    "        l.get_frame().set_linewidth(0.0)\n",
    "        l.set_bbox_to_anchor([0.62, 0.48], transform = ax.transAxes)\n",
    "        l.get_title().set_text(None)\n",
    "        if k != 0:\n",
    "            l.remove()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(f\"{odir}/kennicott_param_hists_prior_posterior.pdf\")\n",
    "del fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e20d8b87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<Axes: xlabel='b_low', ylabel='Probability'>,\n",
       "       <Axes: xlabel='b_high', ylabel='Probability'>,\n",
       "       <Axes: xlabel='ela', ylabel='Probability'>,\n",
       "       <Axes: xlabel='temp_ela', ylabel='Probability'>], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "axs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38b8b01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = l.get_title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f6d8d127",
   "metadata": {},
   "outputs": [],
   "source": [
    "title.set_text(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dc56cff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!open 2023_06_23_uq_climate_flow/*.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91e1aa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
